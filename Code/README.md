# NLU Task 1: Building a Language Model
## Authors: Group 04
1. Leopold Franz 
2. Felix Graule 
3. Rhea Sukthanker
4. Esref Ã–zdemir

## Project Structure
We have separated the logic into several files. A quick summary of each file is as follows:

* `config_ref.json`: Configuration file. You can change training/testing parameters/files/etc. in this file.
* `data`: Main data folder. Put the training/testing files into this folder. Note that names given in `config_ref.json`
must match the filenames. (We have used different filenames than the ones given to us; so just putting the datafiles
with the original names won't work).
* `experiment_configs`: Folder with example config files for each of the experiments. This folder is not required by
itself to run the project.
* `data_handler.py`: This is the class used for reading training/evaluation/testing data. It performs normalization
if necessary, and provides the python iterator interface for accessing data in batches.
* `load_embedding.py`: Embedding loading script given to us (no changes have been made).
* `lstm.py`: LSTM model class. This class implements the core training/prediction/conditional generation logic in
tensorflow. We have decided to perform conditional generation solely in tensorflow using masks, and do the <eos> end
logic in conditional generation afterwards.
* `main_test.py`: This is the main file for perplexity calculation on test file and conditional generation on
continuation file. Just change the appropriate parameters in `config_ref.json` to run the corresponding experiment. The
following changes are needed:
  1. Set training experiment type. (one of a, b, c)
  2. Set test experiment type. (one of evaluate, `cond_gen`)
  3. Set test data file or continuation data file path.
  4. Set vocab handler path. Vocabulary generated during training is pickled and stored so that it can be loaded during
  testing.
  5. Set the checkpoint path of the trained model.
* `main_train.py`: This is the main file for training the model. Change the following parameters:
  1. Set the training experiment type (one of a, b, c)
  2. Set train and eval data file paths. (both needed)
  3. Set word2vec embeddings path
* `tags.py`: Just some tags definitions.
* `util.py`: This file contains the perplexity calculation. We calculate perplexity of all sentences in a given
batch of sentences.
* `vocab_handler.py`: This is the class used for handling vocabulary building and (word <--> index) mapping.

## Running
After doing the changes in `config_ref.json` required for training, you can train the model simply by running
`python main_train.py`.  Similarly, after doing the changes in `config_ref.json` required for testing, you can test
the model simply by running `python main_test.py`. For conditional generation run `python main_test.py` with experiment 
type in `config_ref.json` set to `cond_gen`
